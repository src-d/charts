# Default values for spark.
# This is a YAML-formatted file.
# Declare name/value pairs to be passed into your templates.
# name: value

Master:
  Name: master
  Image: "srcd/spark"
  ImageTag: "2.2.0_v2"
  Replicas: 1
  Component: "spark-master"
  Cpu: "100m"
  Memory: "512Mi"
  ServicePort: 7077
  ContainerPort: 7077
  # Additional volumes for the Master pod
  additionalVolumes: []
  # Additional volume mounts for the Master container
  additionalVolumeMounts: []
  # Custom Spark Config. See template to find which values are already set
  customSparkConfig: {}
  # Set Master JVM memory. Default 1g
  #DaemonMemory: 1g
  #NodeSelector:
    #srcd.host/type: service


# Enable Livy http rest service connected to spark-master
Livy: 
  Enabled: false
  Name: livy
  Image: "srcd/spark-livy"
  ImageTag: "2.2.3"
  ServicePort: 8998
  ContainerPort: 8998

WebUi:
  Name: webui
  ServicePort: 8080
  ContainerPort: 8080

WebUiProxy:
  Name: "webui-proxy"
  ServiceType: ClusterIP
  ServicePort: 80
  ContainerPort: 80
  # ServiceNodePort: 
  Component: "spark-webui-proxy"
  Replicas: 1
  Image: "srcd/spark-ui-proxy"
  ImageTag: "1.2.0"
  Cpu: "100m"
  ReverseProxy:
    Deploy: true
    Debug: false
    # This will make spark-web-ui-proxy work with kubectl proxy --api-prefix
    # which is something that always should be set when working when kubectl proxy
    # ApiPrefix: spark-ui-proxy
  #NodeSelector:
    #srcd.host/type: worker

Worker:
  Name: worker
  Image: "srcd/spark"
  ImageTag: "2.2.0_v2"
  Replicas: 1
  Component: "spark-worker"
  Cpu: "100m"
  Memory: "512Mi"
  ContainerPort: 8081
  # Custom Spark Config. See template to find which values are already set
  customSparkConfig: {}
  # Set Spark's temporary files location
  TemporaryDirRoot: /tmp
  # Additional volumes for the Worker pods
  additionalVolumes: []
  # Additional volume mounts for the Worker container
  additionalVolumeMounts: []
  # Set Worker JVM memory. Default 1g
  #DaemonMemory: 1g
  # Set how much total memory workers have to give executors
  #ExecutorMemory: 1g
  #NodeSelector:
  #  srcd.host/type: worker
  #AdditionalPodContainers:
  #  bblfsh-server:
  #    image: bblfsh/server:latest
  #    securityContext:
  #      privileged: true
  ## Affinity for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ##
  Affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - spark
          topologyKey: kubernetes.io/hostname
